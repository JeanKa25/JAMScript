Testing (already completed modules):
    C->C: Local task testing. Local tasks can be of two types: blocking
    (synchronous) and non-blocking (asynchronous). The blocking tasks give a
    value as a result and other one does not. We have both implemented and are
    passing simple testing. Extreme testing is necessary to PASS both as done
    and valid for the new implementation.  In particular, argument passing and
    result passing needs to be tested very carefully to make sure all types are
    handled properly.

    C->J: Worker launching a task on to the controller. This has blocking and
    non-blocking versions as well. The blocking version gives a result and other
    one does not. We have both versions working and basic testing has been done
    on them. In particular, argument passing and result passing needs to be
    tested very carefully to make sure all types are handled properly.

    J->C: Controller launching a task on to the worker in done by this method.
    We have synchronous and asynchronous versions of this call. The synchronous
    call needs the precise scheduling and synchronization portion of the
    runtime. So, only the asynchronous method is implemented. This method just
    launches the call and moves on. We have implemented this and basic tests
    have passed. In particular, argument passing and result passing needs to be
    tested very carefully to make sure all types are handled properly.

    Testing with many combinations. We test under mixed task conditions and at very
    high speeds. This is partially done, but needs to be stressed to extreme levels.

Testing (future):
    For all modules shown below we would have testing. It could be better to
    setup a testing harness that would run all the tests in the test suite.

    Automated feature testing and reporting the errors feature-by-feature. That
    is, we run a test suite and get a report that says which feature of the
    runtime is broken or not passing the testing.

Integration testing:
    This is testing with the J-Core and the whole compiler. This would be the
    work of Zhelin (Ericsson Intern). We need to have a basic versions of the
    J-Core and C-Core working to get into integration testing.

Bug fixing:
    Memory leaks:
        Valgrind reports a memory leak because the task board terminates without
        releaseing the task_list entries. At least the tasks that are still in
        progress are held in the task_list when the task board terminates, which
        a memory leak. So, we need to cleanup the task_list with a proper
        destroy and at the same time we need to avoid read after dealloc error
        messages to avoid segfault at close. 

        We also have a problem with the publish_message_buffer. We are not
        properly destroying it. There is a destroy function but it as a read
        after dealloc error. So, we need to resolve it and activate the routine. 

        There are some transient CBOR memory leaks. This could be fixed when we
        move to TinyCBOR. Looks like libCBOR is a bad library with a complicated
        memory allocation structure that is prone to memory problems. 

    Memory fragmentation:
        There is a heap fragmentation problem. So far, it is not bad. After some
        time the heap growth stops. At some point we could revise the code to do
        the allocations in junks, which should help with the fragmentation
        problem.

    CBOR receiver errors:
        Right now when the receive message is non conforming we will have a
        program termination due to assert failure. May be we need to check the
        message for validation and the particular message should be skipped
        without terminating the whole program. So, we need to recover from bad
        messages without terminations, we can throw error messages into the log.

    ##### SOLVED
    Timed wait problem:
        The primary executor goes into timed wait when there are no tasks. Right
        now the timed wait does not wait. The executor breaks out of the wait
        immediately. We need to resolve this problem to avoid the 99% CPU
        utilization.
    ###

Refactoring:
    At this point there is no major code refactoring to be done, which is
    actually a good thing!

    Code comments are outdated. We need to update them and make them Doxygen
    friendly. We need to revise the code to make sure Doxygen output is
    correctly showing up.

Small additions:
    C->J call can have a reachability issue. That is, the worker may be
    disconnected from the controller. We need to implement retries. For ASYNC
    calls, we do retries to get the ACK for the initial call. That is, we keep
    trying for N (=3) times to send the call if the ACK is not received.
    Remember in ASYNC calls we are not seeking any results. For the SYNC calls
    we need the replies and can be retrying a number of times (could be 3)
    before declaring that the method call has failed.

    We also need to keep track of the task execution calls in C->J and relate
    the replies to the calls. This way the reply can be collated to the correct
    reply.

    Termination of taskboard or worker: We need to handle the termination of the
    taskboard. This is done by attaching a "last will" on the MQTT broker. The
    last will is triggered when the J side stops running. The last will
    publishes a kill message and the worker side would process it and terminate
    itself.

    Registration processing. We need to get the registration processing done.
    This could go into the core of the worker. The registration would be
    attached to the unique Node ID (UUID4) of the node. We need to get a worker
    ID from the controller at registration. Which level should we use to get the
    worker ID? For the snowflakeID.. the worker ID part is limited to 1023. So,
    it makes sense to get it from the device controller. A device controller
    would have less than 1024 workers - however there could be more than that
    under an edge controller.

Medium additions:
    Task execution history. Some of the hooks are already built into the task
    board structure. We want to accumulate task execution characteristics. These
    could include average number of cycles spent per task. Distribution of
    cycles across the different stages of a task. May be it would also help to
    gather information on where the stage lies - towards the beginning or end of
    the task, etc. The idea is to have enough information about the task
    execution so that we know whether the application is likely a particular
    task without violating any future deadlines. Also, the information we have
    about the execution time can be used to FUSE some of the execution switches.
    That is, some of the context switches can be eliminated using this
    information. We need to use task execution history is two different ways: we
    need to log a gist of it to the monitoring location in ~/.jamrun folder,
    which would be picked up by the program launching or doing lifecycle
    management of JAMScript programs. The other is that the worker should share
    some of this information with the controller.

    Task list (task table) implementation. Right now the task board does not
    have a task list to keep track of the active tasks. Such a task list is
    sometimes redundant. So, we have to be careful. The active tasks are already
    in the task queue. What purpose is served by a task list? A task list can
    become handy in the following scenario. When we send a remote task we can
    keep the state of the task in the task list. The timer can set to generate
    an alarm. The alarm would send a retry if the reply hasn't arrived by the
    set interval. If the reply isn't coming after certain retries, the task
    would fail. To keep the retries going and to track the execution progress we
    need to the table.

    Synchronization statement implementation. We need implement jsleep(),
    jwait(), jsignal(), jcondsleep() to freeze the execution of a task without
    stopping the executor (virtual processor). This way one task can wait on a
    precedence constraint while other tasks are eligible for execution and make
    forward progress. Also, part of this is a precise sleeper. It is always very
    difficult to precisely sleep. Most sleeps are ensuring that the thread (or
    task in this case) does not resume execution before the specified. How long
    after the specified time, we don't have any idea. With a precise sleeper we
    want to stay very close to the specified time. * jsleep will suspend the
    task for a certain number of micro seconds as specified. * jwait will
    suspend a task waiting for some other event to occur. The event would be
    created by a running task and it would perform a jsignal. * jcondsleep is
    the mix of jsleep and jwait. We could also call this a jtimedwait().

    Synchronization primitives are connected to the task list. When we pause a task
    we need to take it out of the run queue. So, we can use the task_list for holding the task.
    Once the reply comes - event it is waiting has occured we reactivate the task and
    release the task from the task_list. 

    JCond support. We can bring in JCond implementation from the previous
    version into the new C-core. Need to figure out how the JCond code can be
    hooked into the Taskboard code.

Large additions:

    Precision task processing: This is a major feature. We need to approach this
    implementation as follows: develop a precise timer (on the timing wheel),
    scheduler, bid processor, and synchronizer.

    Precise timer: We need to get a precise timer running based on the timing
    wheel. The timing wheel is a data structure that keeps track of all timing
    based events. As we advance the time (i.e., rotate the timing wheel), events
    would get expired that is should have happened. So, we can use the timing
    wheel to order the events by their start times and process them. We would
    use the timing wheel data structure that is already available for C to
    implement our requirement. The immediate requirement is to create a precise
    timing facility that can operate at micro seconds. Also, the timing facility
    should work with task launches. This needs a little bit of design and
    implementation.

    Scheduler: This work would design and implement the scheduler, which is a
    major undertaking. We can start with the FCFS scheduler, which would be the
    default. So, if the L1 side is not pushing any schedules we default to FCFS.
    When we get a schedule from the L1 side it would be for RT (at least) and
    some combined schedules for the batch. So, we need to run the schedules
    accordingly. The question is how would we combine the batch tasks - what
    would be the identity of the batch tasks? The more general situation would
    have RT/SY/FCFS schedules.

    Synchronizer: The synchronizer would be part of the SY implementation. The
    precise timer is the key here.

    Bid processor: The two phases of the schedule needs to be considered here.

    Data processor: The data processor is responsible for pushing the data
    updates for JData from the C-core. It is pushing to the data store and the
    datafield architecture would have an impact on its eventual implementation.
    The data processor is not implementing the data field. It is just pushing
    and pulling the data from the data field.

    Working with multiple controllers: How do we deal with multiple controllers?
`   How is this connected to fault tolerance?

Design:
    Data field design and implementation.

    https://shorturl.at/dewAJ
